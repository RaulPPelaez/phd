% Encoding: windows-1252

@Comment{jabref-meta: databaseType:bibtex;}
@article{cuda,
author = {Nickolls, John and Buck, Ian and Garland, Michael and Skadron, Kevin},
title = {Scalable Parallel Programming with CUDA: Is CUDA the Parallel Programming Model That Application Developers Have Been Waiting For?},
year = {2008},
issue_date = {March/April 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
issn = {1542-7730},
url = {https://doi.org/10.1145/1365490.1365500},
doi = {10.1145/1365490.1365500},
abstract = {The advent of multicore CPUs and manycore GPUs means that mainstream processor chips are now parallel systems. Furthermore, their parallelism continues to scale with Moore’s law. The challenge is to develop mainstream application software that transparently scales its parallelism to leverage the increasing number of processor cores, much as 3D graphics applications transparently scale their parallelism to manycore GPUs with widely varying numbers of cores.},
journal = {Queue},
month = mar,
pages = {40-53},
numpages = {14}
}


@book{opengl,
  title={OpenGL programming guide: the official guide to learning OpenGL, version 1.2},
  author={Woo, Mason and Neider, Jackie and Davis, Tom and Shreiner, Dave},
  year={1999},
  publisher={Addison-Wesley Longman Publishing Co., Inc.}
} 

@INPROCEEDINGS{gpgpu2002,
author={C. J. {Thompson} and  {Sahngyun Hahn} and M. {Oskin}},
booktitle={35th Annual IEEE/ACM International Symposium on Microarchitecture, 2002. (MICRO-35). Proceedings.},
title={Using modern graphics architectures for general-purpose computing: a framework and analysis},
year={2002},
volume={},
number={},
pages={306-317},
doi={10.1109/MICRO.2002.1176259}}

@article{ps3md2009,
author = {Luttmann, Edgar and Ensign, Daniel L. and Vaidyanathan, Vishal and Houston, Mike and Rimon, Noam and Øland, Jeppe and Jayachandran, Guha and Friedrichs, Mark and Pande, Vijay S.},
title = {Accelerating molecular dynamic simulation on the cell processor and Playstation 3},
journal = {Journal of Computational Chemistry},
volume = {30},
number = {2},
pages = {268-274},
keywords = {biophysics, simulation software, molecular dynamics, parallel computation, distributed computing, cell processor},
doi = {https://doi.org/10.1002/jcc.21054},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.21054},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jcc.21054},
abstract = {Abstract Implementation of molecular dynamics (MD) calculations on novel architectures will vastly increase its power to calculate the physical properties of complex systems. Herein, we detail algorithmic advances developed to accelerate MD simulations on the Cell processor, a commodity processor found in PlayStation 3 (PS3). In particular, we discuss issues regarding memory access versus computation and the types of calculations which are best suited for streaming processors such as the Cell, focusing on implicit solvation models. We conclude with a comparison of improved performance on the PS3's Cell processor over more traditional processors. © 2008 Wiley Periodicals, Inc. J Comput Chem, 2009},
year = {2009}
}

@inproceedings{gpuml2005,
author = {Luo, Zhongwen and Liu, Hongzhi and Yang, Zhengping and Wu, Xincai},
year = {2005},
month = {01},
pages = {557-562},
title = {Self-Organizing Maps computing on Graphic Process Unit.}
}

@INPROCEEDINGS{gpuml1998,
    author = {Christian-A. Bohn},
    title = {Kohonen Feature Mapping through Graphics Hardware},
    booktitle = {In Proceedings of Int. Conf. on Compu. Intelligence and Neurosciences},
    year = {1998},
    pages = {64--67}
}

@article{gpuimage2006,
author = {Gonzalez‐Mora,Jose  and Guil,Nicolas  and Zapata,Emilio L. },
title = {Using Graphic Processing Units for Tracking Algorithms},
journal = {AIP Conference Proceedings},
volume = {860},
number = {1},
pages = {310-317},
year = {2006},
doi = {10.1063/1.2361233},

URL = { 
        https://aip.scitation.org/doi/abs/10.1063/1.2361233
    
},
eprint = { 
        https://aip.scitation.org/doi/pdf/10.1063/1.2361233
    
}

}

@inproceedings{gpuimage2003,
author = {Colantoni, Philippe and Boukala, Nabil and Da-Rugna, Jérôme},
year = {2003},
month = {01},
pages = {383-390},
title = {Fast and Accurate Color Images Processing Using 3D Graphics Cards.}
}

@inproceedings{gpulinalg2001,
author = {Larsen, E. Scott and McAllister, David},
title = {Fast Matrix Multiplies Using Graphics Hardware},
year = {2001},
isbn = {158113293X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/582034.582089},
doi = {10.1145/582034.582089},
abstract = {We present a technique for large matrix-matrix multiplies using low cost graphics hardware. The result is computed by literally visualizing the computations of a simple parallel processing algorithm. Current graphics hardware technology has limited precision and thus limits immediate applicability of our algorithm. We include results demonstrating proof of concept, correctness, speedup, and a simple application. This is therefore forward looking research: a technique ready for technology on the horizon.},
booktitle = {Proceedings of the 2001 ACM/IEEE Conference on Supercomputing},
pages = {55},
numpages = {1},
keywords = {graphics hardware, matrix multiplication},
location = {Denver, Colorado},
series = {SC '01}
}

  

@article{gpulinalg2003a,
author = {Bolz, Jeff and Farmer, Ian and Grinspun, Eitan and Schr\"{o}der, Peter},
title = {Sparse Matrix Solvers on the GPU: Conjugate Gradients and Multigrid},
year = {2003},
issue_date = {July 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/882262.882364},
doi = {10.1145/882262.882364},
abstract = {Many computer graphics applications require high-intensity numerical simulation. We show that such computations can be performed efficiently on the GPU, which we regard as a full function streaming processor with high floating-point performance. We implemented two basic, broadly useful, computational kernels: a sparse matrix conjugate gradient solver and a regular-grid multigrid solver. Real time applications ranging from mesh smoothing and parameterization to fluid solvers and solid mechanics can greatly benefit from these, evidence our example applications of geometric flow and fluid simulation running on NVIDIA's GeForce FX.},
journal = {ACM Trans. Graph.},
month = jul,
pages = {917-924},
numpages = {8},
keywords = {Navier-Stokes, multigrid, fluid simulation, conjugate gradient, mesh smoothing, numerical simulation, GPU computing}
}

  



@article{gpulinalg2003b,
author = {Bolz, Jeff and Farmer, Ian and Grinspun, Eitan and Schr\"{o}der, Peter},
title = {Sparse Matrix Solvers on the GPU: Conjugate Gradients and Multigrid},
year = {2003},
issue_date = {July 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/882262.882364},
doi = {10.1145/882262.882364},
abstract = {Many computer graphics applications require high-intensity numerical simulation. We show that such computations can be performed efficiently on the GPU, which we regard as a full function streaming processor with high floating-point performance. We implemented two basic, broadly useful, computational kernels: a sparse matrix conjugate gradient solver and a regular-grid multigrid solver. Real time applications ranging from mesh smoothing and parameterization to fluid solvers and solid mechanics can greatly benefit from these, evidence our example applications of geometric flow and fluid simulation running on NVIDIA's GeForce FX.},
journal = {ACM Trans. Graph.},
month = jul,
pages = {917-924},
numpages = {8},
keywords = {multigrid, numerical simulation, conjugate gradient, fluid simulation, mesh smoothing, GPU computing, Navier-Stokes}
}

  

@INPROCEEDINGS{gpulbm2004,

  author={ {Zhe Fan} and  {Feng Qiu} and A. {Kaufman} and S. {Yoakum-Stover}},

  booktitle={SC '04: Proceedings of the 2004 ACM/IEEE Conference on Supercomputing}, 

  title={GPU Cluster for High Performance Computing}, 

  year={2004},

  volume={},

  number={},

  pages={47-47},

  doi={10.1109/SC.2004.26}
 }

@article {virusfullatom2018,
article_type = {journal},
title = {All-atom molecular dynamics of the HBV capsid reveals insights into biological function and cryo-EM resolution limits},
author = {Hadden, Jodi A and Perilla, Juan R and Schlicksup, Christopher John and Venkatakrishnan, Balasubramanian and Zlotnick, Adam and Schulten, Klaus},
editor = {Brunger, Axel T},
volume = 7,
year = 2018,
month = {apr},
pub_date = {2018-04-27},
pages = {e32478},
citation = {eLife 2018;7:e32478},
doi = {10.7554/eLife.32478},
url = {https://doi.org/10.7554/eLife.32478},
abstract = {The hepatitis B virus capsid represents a promising therapeutic target. Experiments suggest the capsid must be flexible to function; however, capsid structure and dynamics have not been thoroughly characterized in the absence of icosahedral symmetry constraints. Here, all-atom molecular dynamics simulations are leveraged to investigate the capsid without symmetry bias, enabling study of capsid flexibility and its implications for biological function and cryo-EM resolution limits. Simulation results confirm flexibility and reveal a propensity for asymmetric distortion. The capsid’s influence on ionic species suggests a mechanism for modulating the display of cellular signals and implicates the capsid’s triangular pores as the location of signal exposure. A theoretical image reconstruction performed using simulated conformations indicates how capsid flexibility may limit the resolution of cryo-EM. Overall, the present work provides functional insight beyond what is accessible to experimental methods and raises important considerations regarding asymmetry in structural studies of icosahedral virus capsids.},
keywords = {Molecular Dynamics Simulation, Hepatitis B Virus, Virus Capsid, Single-Particle Image Reconstruction, Cryo-EM resolution},
journal = {eLife},
issn = {2050-084X},
publisher = {eLife Sciences Publications, Ltd},
}

@article{HighamNumericalSDE,
author = {Higham., Desmond J.},
title = {An Algorithmic Introduction to Numerical Simulation of Stochastic Differential Equations},
journal = {SIAM Review},
volume = {43},
number = {3},
pages = {525-546},
year = {2001},
doi = {10.1137/S0036144500378302},
URL = {https://doi.org/10.1137/S0036144500378302},
eprint = {https://doi.org/10.1137/S0036144500378302}
}

@article{HairerNumericalIntegration,
title={Geometric numerical integration illustrated by the Störmer–Verlet method},
volume={12},
doi={10.1017/S0962492902000144},
journal={Acta Numerica},
publisher={Cambridge University Press},
author={Hairer, Ernst and Lubich, Christian and Wanner, Gerhard},
year={2003},
pages={399-450}
}

@article{Brunger1984,
title = {Stochastic boundary conditions for molecular dynamics simulations of ST2 water},
journal = {Chemical Physics Letters},
volume = {105},
number = {5},
pages = {495-500},
year = {1984},
issn = {0009-2614},
doi = {https://doi.org/10.1016/0009-2614(84)80098-6},
url = {https://www.sciencedirect.com/science/article/pii/0009261484800986},
author = {Axel Brünger and Charles L. Brooks and Martin Karplus},
abstract = {The deformable stochastic boundary method developed previously for treating simple liquids without periodic boundary conditions, is extended to the ST2 model of water. The method is illustrated by a molecular dynamics simulation of a sphere containing 98 water molecules. Comparison with the results of the periodic boundary simulation by Stillinger and Rahman shows very good agreement for structural and dynamic properties.}
}
@article{Wang2003,
author = { Wei Wang  and  Robert D. Skeel},
title = {Analysis of a few numerical integration methods for the Langevin equation},
journal = {Molecular Physics},
volume = {101},
number = {14},
pages = {2149-2156},
year  = {2003},
publisher = {Taylor & Francis},
doi = {10.1080/0026897031000135825},
URL = { 
        https://doi.org/10.1080/0026897031000135825
    
},
eprint = { 
        https://doi.org/10.1080/0026897031000135825
    
}
}
@article{Gronbech2013,
author = { Niels   Grønbech-Jensen  and  Oded   Farago },
title = {A simple and effective Verlet-type algorithm for simulating Langevin dynamics},
journal = {Molecular Physics},
volume = {111},
number = {8},
pages = {983-991},
year  = {2013},
publisher = {Taylor & Francis},
doi = {10.1080/00268976.2012.760055},

URL = { 
        https://doi.org/10.1080/00268976.2012.760055
    
},
eprint = { 
        https://doi.org/10.1080/00268976.2012.760055
    
}

}



@article{Leimhuler2015,
title = {On the numerical treatment of dissipative particle dynamics and related systems},
journal = {Journal of Computational Physics},
volume = {280},
pages = {72-95},
year = {2015},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2014.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0021999114006445},
author = {Benedict Leimkuhler and Xiaocheng Shang},
keywords = {Dissipative particle dynamics, Pairwise Nosé–Hoover–Langevin thermostat, Order of convergence, Weak order, Configurational temperature, Momentum conservation, Stochastic differential equations, Molecular dynamics},
abstract = {We review and compare numerical methods that simultaneously control temperature while preserving the momentum, a family of particle simulation methods commonly used for the modelling of complex fluids and polymers. The class of methods considered includes dissipative particle dynamics (DPD) as well as extended stochastic-dynamics models incorporating a generalized pairwise thermostat scheme in which stochastic forces are eliminated and the coefficient of dissipation is treated as an additional auxiliary variable subject to a feedback (kinetic energy) control mechanism. In the latter case, we consider the addition of a coupling of the auxiliary variable, as in the Nosé–Hoover–Langevin (NHL) method, with stochastic dynamics to ensure ergodicity, and find that the convergence of ensemble averages is substantially improved. To this end, splitting methods are developed and studied in terms of their thermodynamic accuracy, two-point correlation functions, and convergence. In terms of computational efficiency as measured by the ratio of thermodynamic accuracy to CPU time, we report significant advantages in simulation for the pairwise NHL method compared to popular alternative schemes (up to an 80% improvement), without degradation of convergence rate. The momentum-conserving thermostat technique described here provides a consistent hydrodynamic model in the low-friction regime, but it will also be of use in both equilibrium and nonequilibrium molecular simulation applications owing to its efficiency and simple numerical implementation.}
}
@article{Besold2000,
  title = {Towards better integrators for dissipative particle dynamics simulations},
  author = {Besold, Gerhard and Vattulainen, Ilpo and Karttunen, Mikko and Polson, James M.},
  journal = {Phys. Rev. E},
  volume = {62},
  issue = {6},
  pages = {R7611--R7614},
  numpages = {0},
  year = {2000},
  month = {Dec},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.62.R7611},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.62.R7611}
}

@article{Espanol1995,
	doi = {10.1209/0295-5075/30/4/001},
	url = {https://doi.org/10.1209/0295-5075/30/4/001},
	year = 1995,
	month = {may},
	publisher = {{IOP} Publishing},
	volume = {30},
	number = {4},
	pages = {191--196},
	author = {P Espa{\~{n}}ol and P Warren},
	title = {Statistical Mechanics of Dissipative Particle Dynamics},
	journal = {Europhysics Letters ({EPL})},
	abstract = {The stochastic differential equations corresponding to the updating algorithm of Dissipative Particle Dynamics (DPD), and the corresponding Fokker-Planck equation are derived. It is shown that a slight modification to the algorithm is required before the Gibbs distribution is recovered as the stationary solution to the Fokker-Planck equation. The temperature of the system is then directly related to the noise amplitude by means of a fluctuation-dissipation theorem. However, the correspondingly modified, discrete DPD algorithm is only found to obey these predictions if the length of the time step is sufficiently reduced. This indicates the importance of time discretisation in DPD.}
}






@article{Groot1997,
author = {Groot,Robert D.  and Warren,Patrick B. },
title = {Dissipative particle dynamics: Bridging the gap between atomistic and mesoscopic simulation},
journal = {The Journal of Chemical Physics},
volume = {107},
number = {11},
pages = {4423-4435},
year = {1997},
doi = {10.1063/1.474784},

URL = { 
        https://doi.org/10.1063/1.474784
    
},
eprint = { 
        https://doi.org/10.1063/1.474784
    
}

}

@article{Pagonabarraga1998,
	doi = {10.1209/epl/i1998-00258-6},
	url = {https://doi.org/10.1209/epl/i1998-00258-6},
	year = 1998,
	month = {may},
	publisher = {{IOP} Publishing},
	volume = {42},
	number = {4},
	pages = {377--382},
	author = {I Pagonabarraga and M. H. J Hagen and D Frenkel},
	title = {Self-consistent dissipative particle dynamics algorithm},
	journal = {Europhysics Letters ({EPL})},
	abstract = {We propose an implementation of dissipative particle dynamics that is free of the inconsistencies that plagued earlier algorithms. The present algorithm satisfies a form of microscopic reversibility. As a consequence, we recover the correct equilibrium properties. Moreover, we can use much larger time steps than previously. We report a detailed comparison between simulated transport properties and the theoretical predictions. We find that the existing theory is only valid under very special conditions. A more general theory is still lacking.}
}
@article{Desmond2001,
author = {Higham., Desmond J.},
title = {An Algorithmic Introduction to Numerical Simulation of Stochastic Differential Equations},
journal = {SIAM Review},
volume = {43},
number = {3},
pages = {525-546},
year = {2001},
doi = {10.1137/S0036144500378302},

URL = { 
        https://doi.org/10.1137/S0036144500378302
    
},
eprint = { 
        https://doi.org/10.1137/S0036144500378302
    
}
}

@book{Kloeden2011,
  title={Numerical Solution of Stochastic Differential Equations},
  author={Kloeden, P.E. and Platen, E.},
  isbn={978-3-662-12616-5},
  lccn={92015916},
  series={Stochastic Modelling and Applied Probability},
  url={https://link.springer.com/book/10.1007%2F978-3-662-12616-5},
  year={2011},
  publisher={Springer Berlin Heidelberg}
}
@article{Balboa2017,
author = {Balboa Usabiaga,Florencio  and Delmotte,Blaise  and Donev,Aleksandar },
title = {Brownian dynamics of confined suspensions of active microrollers},
journal = {The Journal of Chemical Physics},
volume = {146},
number = {13},
pages = {134104},
year = {2017},
doi = {10.1063/1.4979494},

URL = { 
        https://doi.org/10.1063/1.4979494
    
},
eprint = { 
        https://doi.org/10.1063/1.4979494
    
}

}

@article{Leimkuhler2015,
    author = {Leimkuhler, Benedict and Matthews, Charles and Stoltz, Gabriel},
    title = "{The computation of averages from equilibrium and nonequilibrium Langevin molecular dynamics}",
    journal = {IMA Journal of Numerical Analysis},
    volume = {36},
    number = {1},
    pages = {13-79},
    year = {2015},
    month = {01},
    abstract = "{We consider numerical methods for thermodynamic sampling, i.e., computing sequences of points distributed according to the Gibbs–Boltzmann distribution, using Langevin dynamics and overdamped Langevin dynamics (Brownian dynamics). A wide variety of numerical methods for Langevin dynamics may be constructed based on splitting the stochastic differential equations into various component parts, each of which may be propagated exactly in the sense of distributions. Each such method may be viewed as generating samples according to an associated invariant measure that differs from the exact canonical invariant measure by a stepsize-dependent perturbation. We provide error estimates à la Talay–Tubaro on the invariant distribution for small stepsize, and compare the sampling bias obtained for various choices of the splitting method. We further investigate the overdamped limit and apply the methods in the context of driven systems where the goal is sampling with respect to a nonequilibrium steady state. Our analyses are illustrated by numerical experiments.}",
    issn = {0272-4979},
    doi = {10.1093/imanum/dru056},
    url = {https://doi.org/10.1093/imanum/dru056},
    eprint = {https://academic.oup.com/imajna/article-pdf/36/1/13/7920471/dru056.pdf},
}

@article{Delong2013,
  title = {Temporal integrators for fluctuating hydrodynamics},
  author = {Delong, Steven and Griffith, Boyce E. and Vanden-Eijnden, Eric and Donev, Aleksandar},
  journal = {Phys. Rev. E},
  volume = {87},
  issue = {3},
  pages = {033302},
  numpages = {22},
  year = {2013},
  month = {Mar},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.87.033302},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.87.033302}
}

@article{Anderson2008,
title = {General purpose molecular dynamics simulations fully implemented on graphics processing units},
journal = {Journal of Computational Physics},
volume = {227},
number = {10},
pages = {5342-5359},
year = {2008},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2008.01.047},
url = {https://www.sciencedirect.com/science/article/pii/S0021999108000818},
author = {Joshua A. Anderson and Chris D. Lorenz and A. Travesset},
keywords = {Graphics processing unit, GPU, NVIDIA, CUDA, Molecular dynamics, Polymer systems},
abstract = {Graphics processing units (GPUs), originally developed for rendering real-time effects in computer games, now provide unprecedented computational power for scientific applications. In this paper, we develop a general purpose molecular dynamics code that runs entirely on a single GPU. It is shown that our GPU implementation provides a performance equivalent to that of fast 30 processor core distributed memory cluster. Our results show that GPUs already provide an inexpensive alternative to such clusters and discuss implications for the future.}
}
@article{Dominguez2011,
author = {Domínguez, J. M. and Crespo, A. J. C. and Gómez-Gesteira, M. and Marongiu, J. C.},
title = {Neighbour lists in smoothed particle hydrodynamics},
journal = {International Journal for Numerical Methods in Fluids},
volume = {67},
number = {12},
pages = {2026-2042},
keywords = {SPH, meshless methods, neighbour list, Verlet list},
doi = {https://doi.org/10.1002/fld.2481},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/fld.2481},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/fld.2481},
abstract = {Abstract Since smoothed particle hydrodynamics (SPH) is based on interactions with the closer neighbouring particles, implementing the neighbour list is a key point in terms of the high performance of the code. The efficiency of the method depends directly on how to build and use the neighbour list. In the present work, the available searching algorithms for SPH codes are analyzed. Different gridding algorithms are evaluated, the gains in efficiency obtained from reordering of particles is investigated and the cell-linked list and Verlet list methods are studied to create the neighbour list. Furthermore, an innovative searching procedure based on a dynamic updating of the Verlet list is proposed. The efficiency of the algorithms is analyzed in terms of computational time and memory requirements. Copyright © 2010 John Wiley \& Sons, Ltd.},
year = {2011}
}
@article{Howard2016,
title = {Efficient neighbor list calculation for molecular simulation of colloidal systems using graphics processing units},
journal = {Computer Physics Communications},
volume = {203},
pages = {45-52},
year = {2016},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2016.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0010465516300182},
author = {Michael P. Howard and Joshua A. Anderson and Arash Nikoubashman and Sharon C. Glotzer and Athanassios Z. Panagiotopoulos},
keywords = {Molecular simulation, Colloid, Size disparity, Non-uniform, Neighbor list, Bounding volume hierarchy, GPU},
abstract = {We present an algorithm based on linear bounding volume hierarchies (LBVHs) for computing neighbor (Verlet) lists using graphics processing units (GPUs) for colloidal systems characterized by large size disparities. We compare this to a GPU implementation of the current state-of-the-art CPU algorithm based on stenciled cell lists. We report benchmarks for both neighbor list algorithms in a Lennard-Jones binary mixture with synthetic interaction range disparity and a realistic colloid solution. LBVHs outperformed the stenciled cell lists for systems with moderate or large size disparity and dilute or semidilute fractions of large particles, conditions typical of colloidal systems.}
}
@article{Brown2011,
title = {Implementing molecular dynamics on hybrid high performance computers – short range forces},
journal = {Computer Physics Communications},
volume = {182},
number = {4},
pages = {898-911},
year = {2011},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2010.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0010465510005102},
author = {W. Michael Brown and Peng Wang and Steven J. Plimpton and Arnold N. Tharrington},
keywords = {Molecular dynamics, GPU, Hybrid parallel computing},
abstract = {The use of accelerators such as graphics processing units (GPUs) has become popular in scientific computing applications due to their low cost, impressive floating-point capabilities, high memory bandwidth, and low electrical power requirements. Hybrid high-performance computers, machines with more than one type of floating-point processor, are now becoming more prevalent due to these advantages. In this work, we discuss several important issues in porting a large molecular dynamics code for use on parallel hybrid machines – (1) choosing a hybrid parallel decomposition that works on central processing units (CPUs) with distributed memory and accelerator cores with shared memory, (2) minimizing the amount of code that must be ported for efficient acceleration, (3) utilizing the available processing power from both multi-core CPUs and accelerators, and (4) choosing a programming model for acceleration. We present our solution to each of these issues for short-range force calculation in the molecular dynamics package LAMMPS, however, the methods can be applied in many molecular dynamics codes. Specifically, we describe algorithms for efficient short range force calculation on hybrid high-performance machines. We describe an approach for dynamic load balancing of work between CPU and accelerator cores. We describe the Geryon library that allows a single code to compile with both CUDA and OpenCL for use on a variety of accelerators. Finally, we present results on a parallel test cluster containing 32 Fermi GPUs and 180 CPU cores.}
}
@article{Tang2014,
title = {Accelerating dissipative particle dynamics simulations on GPUs: Algorithms, numerics and applications},
journal = {Computer Physics Communications},
volume = {185},
number = {11},
pages = {2809-2822},
year = {2014},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2014.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0010465514002203},
author = {Yu-Hang Tang and George Em Karniadakis},
keywords = {DPD, CUDA, LAMMPS, Spontaneous vesicle formation},
abstract = {We present a scalable dissipative particle dynamics simulation code, fully implemented on the Graphics Processing Units (GPUs) using a hybrid CUDA/MPI programming model, which achieves 10–30 times speedup on a single GPU over 16 CPU cores and almost linear weak scaling across a thousand nodes. A unified framework is developed within which the efficient generation of the neighbor list and maintaining particle data locality are addressed. Our algorithm generates strictly ordered neighbor lists in parallel, while the construction is deterministic and makes no use of atomic operations or sorting. Such neighbor list leads to optimal data loading efficiency when combined with a two-level particle reordering scheme. A faster in situ generation scheme for Gaussian random numbers is proposed using precomputed binary signatures. We designed custom transcendental functions that are fast and accurate for evaluating the pairwise interaction. The correctness and accuracy of the code is verified through a set of test cases simulating Poiseuille flow and spontaneous vesicle formation. Computer benchmarks demonstrate the speedup of our implementation over the CPU implementation as well as strong and weak scalability. A large-scale simulation of spontaneous vesicle formation consisting of 128 million particles was conducted to further illustrate the practicality of our code in real-world applications.
Program summary
Program title: GPU-accelerated DPD Package for LAMMPS Catalogue identifier: AETN_v1_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AETN_v1_0.html Program obtainable from: CPC Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: GNU General Public License, version 3 No. of lines in distributed program, including test data, etc.: 1602716 No. of bytes in distributed program, including test data, etc.: 26489166 Distribution format: tar.gz Programming language: C/C++, CUDA C/C++, MPI. Computer: Any computers having nVidia GPGPUs with compute capability 3.0. Operating system: Linux. Has the code been vectorized or parallelized?: Yes. Number of processors used: 1024 16-core CPUs and 1024 GPUs RAM: 500 Mbytes host memory, 2 Gbytes device memory Supplementary material: The data for the examples discussed in the manuscript is available for download. Classification: 6.5, 12, 16.1, 16.11. Nature of problem: Particle-based simulation of mesoscale systems involving nano/micro-fluids, polymers and spontaneous self-assembly process. Solution method: The system is approximated by a number of coarse-grained particles interacting through pairwise potentials and bonded potentials. Classical mechanics is assumed following Newton’s laws. The evolution of the system is integrated using a time-stepping scheme such as Velocity-Verlet. Restrictions: The code runs only on CUDA GPGPUs with compute capability 3.0. Unusual features: Fully implemented on GPGPUs with significant speedup. Running time: 78 h using 1024 GPGPUs for simulating a 128-million-particle system for 18.4 million time steps.}
}

@book{Nguyen2008,
  title={GPU Gems 3},
  author={Nguyen, H. and NVIDIA Corporation},
  number={v. 3},
  isbn={9780321515261},
  lccn={2007023985},
  series={Lab Companion Series},
  url={https://developer.nvidia.com/gpugems/gpugems3},
  year={2008},
  publisher={Addison-Wesley}
}


@article{Peano1890,
author={Peano, G.},
year={1890},
title={Sur une courbe, qui remplit toute une aire plane},
journal={Mathematische Annalen},
pages={157-160},
volume={36},
issn={1432-1807},
url={https://doi.org/10.1007/BF01199438},
doi={10.1007/BF01199438}
}

@book{Hilbert1935,
author={David Hilbert},
year={1935},
title={Dritter Band: Analysis. Grundlagen der Mathematik. Physik Verschiedenes},
journal={Mathematische Annalen},
pages={157-160},
volume={36},
isbn={9783662384527},
publisher={Springer, Berlin, Heidelberg},
url={https://doi.org/10.1007/978-3-662-38452-7_1},
doi={10.1007/978-3-662-38452-7_1}
}

@article{Morton1966,
author={Guy Macdonald Morton},
year={1966},
title={A computer Oriented Geodetic Data Base; and a New Technique in File Sequencing},
publisher={IBM},
url={https://dominoweb.draco.res.ibm.com/0dabf9473b9c86d48525779800566a39.html}
}

@Misc{cub,
author={Duane Merrill and NVIDIA Corporation},
year={2011},
title={CUB: Cooperative primitives for CUDA C++.}
}

@article{Ha2009,
author = {Ha, Linh and Krüger, Jens and Silva, Claudio},
year = {2009},
month = {12},
pages = {2368-2378},
title = {Fast 4-way parallel radix sorting on GPUs},
volume = {28},
journal = {Comput. Graph. Forum},
doi = {10.1111/j.1467-8659.2009.01542.x}
}
@article{Singh2018,
author = {Singh, Dhirendra and Joshi, Ishan and Choudhary, Jaytrilok},
year = {2018},
month = {12},
pages = {},
title = {Survey of GPU Based Sorting Algorithms},
volume = {46},
journal = {International Journal of Parallel Programming},
doi = {10.1007/s10766-017-0502-5}
}
@article{Merrill2011,
author = {Merrill, Duane and Grimshaw, Andrew},
year = {2011},
month = {06},
pages = {245-272},
title = {High Performance and Scalable Radix Sorting: a Case Study of Implementing Dynamic Parallelism for GPU Computing.},
volume = {21},
journal = {Parallel Processing Letters},
doi = {10.1142/S0129626411000187}
}
@article{Ermak1978,
author = {Ermak,Donald L.  and McCammon,J. A. },
title = {Brownian dynamics with hydrodynamic interactions},
journal = {The Journal of Chemical Physics},
volume = {69},
number = {4},
pages = {1352-1360},
year = {1978},
doi = {10.1063/1.436761},

URL = { 
        https://doi.org/10.1063/1.436761
    
},
eprint = { 
        https://doi.org/10.1063/1.436761
    
}

}



@misc{Lisicki2013,
      title={Four approaches to hydrodynamic Green's functions -- the Oseen tensors}, 
      author={Maciej Lisicki},
      year={2013},
      eprint={1312.6231},
      archivePrefix={arXiv},
      primaryClass={physics.flu-dyn}
}


@article{Rotne1969,
author = {Rotne,Jens  and Prager,Stephen },
title = {Variational Treatment of Hydrodynamic Interaction in Polymers},
journal = {The Journal of Chemical Physics},
volume = {50},
number = {11},
pages = {4831-4837},
year = {1969},
doi = {10.1063/1.1670977},

URL = { 
        https://doi.org/10.1063/1.1670977
    
},
eprint = { 
        https://doi.org/10.1063/1.1670977
    
}

}

@article{Yamakawa1970,
author = {Yamakawa,Hiromi },
title = {Transport Properties of Polymer Chains in Dilute Solution: Hydrodynamic Interaction},
journal = {The Journal of Chemical Physics},
volume = {53},
number = {1},
pages = {436-443},
year = {1970},
doi = {10.1063/1.1673799},

URL = { 
        https://doi.org/10.1063/1.1673799
    
},
eprint = { 
        https://doi.org/10.1063/1.1673799
    
}

}


@book{Dhont1996,
  title={An Introduction to Dynamics of Colloids},
  author={Dhont, J.K.G.},
  isbn={9780080535074},
  series={ISSN},
  url={https://www.elsevier.com/books/an-introduction-to-dynamics-of-colloids/dhont/978-0-444-82009-9},
  year={1996},
  publisher={Elsevier Science}
}

@article{Zuk2014,
author = {Zuk, Pawel and Wajnryb, Eligiusz and Mizerski, Krzysztof and Szymczak, Piotr},
year = {2014},
month = {02},
pages = {R5},
title = {Rotne-Prager-Yamakawa approximation for different-sized particles in application to macromolecular bead models},
volume = {741},
journal = {Journal of Fluid Mechanics},
doi = {10.1017/jfm.2013.668}
}
@article{Wajnryb2013,
title={Generalization of the Rotne–Prager–Yamakawa mobility and shear disturbance tensors},
volume={731},
DOI={10.1017/jfm.2013.402},
journal={Journal of Fluid Mechanics},
publisher={Cambridge University Press},
author={Wajnryb, Eligiusz and Mizerski, Krzysztof A. and Zuk, Pawel J. and Szymczak, Piotr},
year={2013},
pages={R3}
}

@article{Liang2013,
title = {A fast multipole method for the Rotne–Prager–Yamakawa tensor and its applications},
journal = {Journal of Computational Physics},
volume = {234},
pages = {133-139},
year = {2013},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2012.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S0021999112005529},
author = {Zhi Liang and Zydrunas Gimbutas and Leslie Greengard and Jingfang Huang and Shidong Jiang},
keywords = {Square root matrix, Fast multipole method, Brownian dynamics, Hydrodynamic interaction, Lanzcos iteration, Krylov subspace approximation, Rotne–Prager–Yamakawa tensor},
abstract = {We present a fast multipole method (FMM) for computing sums involving the Rotne–Prager–Yamakawa tensor. The method, similar to the approach in Tornberg and Greengard (2008) [26] for the Stokeslet, decomposes the tensor vector product into a sum of harmonic potentials and fields induced by four different charge and dipole distributions. Unlike the approach based on the kernel independent fast multipole method (Ying et al., 2004) [31], which requires nine scalar FMM calls, the method presented here requires only four. We discuss its applications to Brownian dynamics simulation with hydrodynamic interactions, and present some timing results.}
}

@article{Guan2018,
title = {RPYFMM: Parallel adaptive fast multipole method for Rotne–Prager–Yamakawa tensor in biomolecular hydrodynamics simulations},
journal = {Computer Physics Communications},
volume = {227},
pages = {99-108},
year = {2018},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2018.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S001046551830033X},
author = {W. Guan and X. Cheng and J. Huang and G. Huber and W. Li and J.A. McCammon and B. Zhang},
keywords = {Brownian dynamics, Rotne–Prager–Yamakawa tensor, Hydrodynamics interactions, Fast multipole method, DASHMM, Distributed computing},
abstract = {RPYFMM is a software package for the efficient evaluation of the potential field governed by the Rotne–Prager–Yamakawa (RPY) tensor interactions in biomolecular hydrodynamics simulations. In our algorithm, the RPY tensor is decomposed as a linear combination of four Laplace interactions, each of which is evaluated using the adaptive fast multipole method (FMM) (Greengard and Rokhlin, 1997) where the exponential expansions are applied to diagonalize the multipole-to-local translation operators. RPYFMM offers a unified execution on both shared and distributed memory computers by leveraging the DASHMM library (DeBuhr et al., 2016, 2018). Preliminary numerical results show that the interactions for a molecular system of 15 million particles (beads) can be computed within one second on a Cray XC30 cluster using 12,288 cores, while achieving approximately 54% strong-scaling efficiency.
Program summary
Program Title: RPYFMM: Parallel Adaptive FMM for RPY Tensor Program Files doi: http://dx.doi.org/10.17632/zpbjvy8whp.1 Licensing provisions: BSD 3-clause Programming language: C++ Nature of problem: Evaluate the Rotne–Prager–Yamakawa tensor matrix–vector multiplications describing the hydrodynamics interaction in biomolecular systems. Solution method: The Rotne–Prager–Yamakawa tensor is decomposed as a linear combination of four Laplace interactions, each of which is evaluated using the new version of adaptive fast multipole method [1]. Additional Comments: RPYFMM is built on top of the DASHMM library and the Asynchronous Multi-Tasking HPX-5 runtime system. DASHMM is automatically downloaded during installation and HPX-5 is available at http://hpx.crest.iu.edu/.}
}

@article{Fiore2017,
author = {Fiore,Andrew M.  and Balboa Usabiaga,Florencio  and Donev,Aleksandar  and Swan,James W. },
title = {Rapid sampling of stochastic displacements in Brownian dynamics simulations},
journal = {The Journal of Chemical Physics},
volume = {146},
number = {12},
pages = {124116},
year = {2017},
doi = {10.1063/1.4978242},

URL = { 
        https://doi.org/10.1063/1.4978242
    
},
eprint = { 
        https://doi.org/10.1063/1.4978242
    
}

}
@article{Saadat2014,
author = {Saadat,Amir  and Khomami,Bamin },
title = {Computationally efficient algorithms for incorporation of hydrodynamic and excluded volume interactions in Brownian dynamics simulations: A comparative study of the Krylov subspace and Chebyshev based techniques},
journal = {The Journal of Chemical Physics},
volume = {140},
number = {18},
pages = {184903},
year = {2014},
doi = {10.1063/1.4873999},

URL = { 
        https://doi.org/10.1063/1.4873999
    
},
eprint = { 
        https://doi.org/10.1063/1.4873999
    
}

}
@article{Fixman1986,
author = {Fixman, Marshall},
title = {Construction of Langevin forces in the simulation of hydrodynamic interaction},
journal = {Macromolecules},
volume = {19},
number = {4},
pages = {1204-1207},
year = {1986},
doi = {10.1021/ma00158a043},

URL = { 
        https://doi.org/10.1021/ma00158a043
    
},
eprint = { 
        https://doi.org/10.1021/ma00158a043
    
}

}

@article{Jendrejack2000,
author = {Jendrejack,Richard M.  and Graham,Michael D.  and de Pablo,Juan J. },
title = {Hydrodynamic interactions in long chain polymers: Application of the Chebyshev polynomial approximation in stochastic simulations},
journal = {The Journal of Chemical Physics},
volume = {113},
number = {7},
pages = {2894-2900},
year = {2000},
doi = {10.1063/1.1305884},

URL = { 
        https://doi.org/10.1063/1.1305884
    
},
eprint = { 
        https://doi.org/10.1063/1.1305884
    
}

}


@article{Ando2012,
author = {Ando,Tadashi  and Chow,Edmond  and Saad,Yousef  and Skolnick,Jeffrey },
title = {Krylov subspace methods for computing hydrodynamic interactions in Brownian dynamics simulations},
journal = {The Journal of Chemical Physics},
volume = {137},
number = {6},
pages = {064106},
year = {2012},
doi = {10.1063/1.4742347},

URL = { 
        https://doi.org/10.1063/1.4742347
    
},
eprint = { 
        https://doi.org/10.1063/1.4742347
    
}

}

@Misc{cusolver,
author={{NVIDIA Corporation}},
year={2014},
title={The NVIDIA cuSolver CUDA library.}
}

@Misc{cufft,
author={{NVIDIA Corporation}},
year={2014},
title={The NVIDIA cuFFT CUDA library.}
}

@Misc{cublas,
author={{NVIDIA Corporation}},
year={2014},
title={The NVIDIA cuBLAS CUDA library.}
}


@article{Lindbo2011,
title = {Spectral accuracy in fast Ewald-based methods for particle simulations},
journal = {Journal of Computational Physics},
volume = {230},
number = {24},
pages = {8744-8761},
year = {2011},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2011.08.022},
url = {https://www.sciencedirect.com/science/article/pii/S0021999111005092},
author = {Dag Lindbo and Anna-Karin Tornberg},
keywords = {Ewald summation, FFT, Spectral accuracy, PME, SPME, Molecular dynamics},
abstract = {A spectrally accurate fast method for electrostatic calculations under periodic boundary conditions is presented. We follow the established framework of FFT-based Ewald summation, but obtain a method with an important decoupling of errors: it is shown, for the proposed method, that the error due to frequency domain truncation can be separated from the approximation error added by the fast method. This has the significance that the truncation of the underlying Ewald sum prescribes the size of the grid used in the FFT-based fast method, which clearly is the minimal grid. Both errors are of exponential-squared order, and the latter can be controlled independently of the grid size. We compare numerically to the established SPME method by Essmann et al. and see that the memory required can be reduced by orders of magnitude. We also benchmark efficiency (i.e. error as a function of computing time) against the SPME method, which indicates that our method is competitive. Analytical error estimates are proven and used to select parameters with a great degree of reliability and ease.}
}

@article{Tornberg2015,
author={Tornberg, Anna-Karin},
abstract={When evaluating the electrostatic potential, periodic boundary conditions in one, two or three of the spatial dimensions are often required for different applications. The triply periodic Ewald summation formula is classical, and Ewald summation formulas for the other two cases have also been derived. In this paper, derivations of the Ewald sums in the doubly and singly periodic cases are presented in a uniform framework based on Fourier analysis, which also yields a natural starting point for FFT-based fast summation methods.},
title={The Ewald sums for singly, doubly and triply periodic electrostatic systems},
journal={Advances in Computational Mathematics},
doi={10.1007/s10444-015-9422-3},
year={2015},
url={https://www.deepdyve.com/lp/springer-journals/the-ewald-sums-for-singly-doubly-and-triply-periodic-electrostatic-R0y3ma0agS},
pages={227,248},
volume={42}
}


@article{Keaveny2014,
title = {Fluctuating force-coupling method for simulations of colloidal suspensions},
journal = {Journal of Computational Physics},
volume = {269},
pages = {61-79},
year = {2014},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2014.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0021999114001867},
author = {Eric E. Keaveny},
keywords = {Brownian motion, Fluctuating stress, Multipoles, Regularisation methods, Stokes flow, Suspensions, Colloids},
abstract = {The resolution of Brownian motion in simulations of micro-particle suspensions can be crucial to reproducing the correct dynamics of individual particles, as well as providing an accurate characterisation of suspension properties. Including these effects in simulations, however, can be computationally intensive due to the configuration dependent random displacements that would need to be determined at every time step. In this paper, we introduce the fluctuating force-coupling method (FCM) to overcome this difficulty, providing a fast approach to simulate colloidal suspensions at large-scale. We show explicitly that by forcing the surrounding fluid with a fluctuating stress and employing the FCM framework to obtain the motion of the particles, one obtains the random particle velocities and angular velocities that satisfy the fluctuation–dissipation theorem. This result holds even when higher-order multipoles, such as stresslets, are included in the FCM approximation. Through several numerical experiments, we confirm our analytical results and demonstrate the effectiveness of fluctuating FCM, showing also how Brownian drift can be resolved by employing the appropriate time integration scheme and conjugate gradient method.}
}

@article{Delong2014,
author = {Delong,Steven  and Usabiaga,Florencio Balboa  and Delgado-Buscalioni,Rafael  and Griffith,Boyce E.  and Donev,Aleksandar },
title = {Brownian dynamics without Green's functions},
journal = {The Journal of Chemical Physics},
volume = {140},
number = {13},
pages = {134110},
year = {2014},
doi = {10.1063/1.4869866},
URL = {https://doi.org/10.1063/1.4869866},
eprint = {https://doi.org/10.1063/1.4869866}
}

@article{Hasimoto1959,
title={On the periodic fundamental solutions of the Stokes equations and their application to viscous flow past a cubic array of spheres},
volume={5},
doi={10.1017/S0022112059000222},
URL={https://doi.org/10.1017/S0022112059000222},
number={2},
journal={Journal of Fluid Mechanics},
publisher={Cambridge University Press},
author={Hasimoto, H.},
year={1959},
pages={317-328}
}

@article{Wang2016,
title = {Spectral Ewald Acceleration of Stokesian Dynamics for polydisperse suspensions},
journal = {Journal of Computational Physics},
volume = {306},
pages = {443-477},
year = {2016},
issn = {0021-9991},
doi = {10.1016/j.jcp.2015.11.042},
url = {https://www.sciencedirect.com/science/article/pii/S0021999115007822},
author = {Mu Wang and John F. Brady},
keywords = {Stokes flow, Stokesian Dynamics, Brownian Dynamics, GPU computation, Ewald summation, Colloidal suspensions},
abstract = {In this work we develop the Spectral Ewald Accelerated Stokesian Dynamics (SEASD), a novel computational method for dynamic simulations of polydisperse colloidal suspensions with full hydrodynamic interactions. SEASD is based on the framework of Stokesian Dynamics (SD) with extension to compressible solvents, and uses the Spectral Ewald (SE) method [Lindbo and Tornberg (2010) [29]] for the wave-space mobility computation. To meet the performance requirement of dynamic simulations, we use Graphic Processing Units (GPU) to evaluate the suspension mobility, and achieve an order of magnitude speedup compared to a CPU implementation. For further speedup, we develop a novel far-field block-diagonal preconditioner to reduce the far-field evaluations in the iterative solver, and SEASD-nf, a polydisperse extension of the mean-field Brownian approximation of Banchio and Brady (2003) [39]. We extensively discuss implementation and parameter selection strategies in SEASD, and demonstrate the spectral accuracy in the mobility evaluation and the overall O(Nlog⁡N) computation scaling. We present three computational examples to further validate SEASD and SEASD-nf in monodisperse and bidisperse suspensions: the short-time transport properties, the equilibrium osmotic pressure and viscoelastic moduli, and the steady shear Brownian rheology. Our validation results show that the agreement between SEASD and SEASD-nf is satisfactory over a wide range of parameters, and also provide significant insight into the dynamics of polydisperse colloidal suspensions.}
}

@article{Lindbo2010,
title = {Spectrally accurate fast summation for periodic Stokes potentials},
journal = {Journal of Computational Physics},
volume = {229},
number = {23},
pages = {8994-9010},
year = {2010},
issn = {0021-9991},
doi = {10.1016/j.jcp.2010.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0021999110004730},
author = {Dag Lindbo and Anna-Karin Tornberg},
keywords = {Viscous flow, Stokes equations, Potential theory, Ewald summation, FFT, Spectral accuracy},
abstract = {A spectrally accurate method for the fast evaluation of N-particle sums of the periodic Stokeslet is presented. Two different decomposition methods, leading to one sum in real space and one in reciprocal space, are considered. An FFT based method is applied to the reciprocal part of the sum, invoking the equivalence of multiplications in reciprocal space to convolutions in real space, thus using convolutions with a Gaussian function to place the point sources on a grid. Due to the spectral accuracy of the method, the grid size needed is low and also in practice, for a fixed domain size, independent of N. The leading cost, which is linear in N, arises from the to-grid and from-grid operations. Combining this FFT based method for the reciprocal sum with the direct evaluation of the real space sum, a spectrally accurate algorithm with a total complexity of O(NlogN) is obtained. This has been shown numerically as the system is scaled up at constant density.}
}

@article{Peskin1977,
title = {Numerical analysis of blood flow in the heart},
journal = {Journal of Computational Physics},
volume = {25},
number = {3},
pages = {220-252},
year = {1977},
issn = {0021-9991},
doi = {https://doi.org/10.1016/0021-9991(77)90100-0},
url = {https://www.sciencedirect.com/science/article/pii/0021999177901000},
author = {Charles S Peskin},
abstract = {The flow pattern of blood in the heart is intimately connected with the performance of the heart valves. This paper extends previous work on the solution of the Navier-Stokes equations in the presence of moving immersed boundaries which interact with the fluid. The boundary representation now includes the muscular heart wall. The fixed topology of the boundary representation is exploited in the solution of the nonlinear equations which implicitly define the boundary forces. An improved numerical representation of the δ-function is introduced. A fast Laplace-solver is used. The results of calculations with a natural valve and with a prosthetic valve are presented.}
}
@article{Peskin2002,
title={The immersed boundary method},
volume={11},
DOI={10.1017/S0962492902000077},
url={https://doi.org/10.1017/S0962492902000077},
journal={Acta Numerica},
publisher={Cambridge University Press},
author={Peskin, Charles S.},
year={2002},
pages={479-517}
}

@article{Bao2016,
title = {A Gaussian-like immersed-boundary kernel with three continuous derivatives and improved translational invariance},
journal = {Journal of Computational Physics},
volume = {316},
pages = {139-144},
year = {2016},
issn = {0021-9991},
doi = {10.1016/j.jcp.2016.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S0021999116300663},
author = {Yuanxun Bao and Jason Kaye and Charles S. Peskin},
keywords = {Immersed boundary method, Fluid–structure interaction, Discrete delta function, Immersed-boundary kernel, Translational invariance},
abstract = {The immersed boundary (IB) method is a general mathematical framework for studying problems involving fluid–structure interactions in which an elastic structure is immersed in a viscous incompressible fluid. In the IB formulation, the fluid described by Eulerian variables is coupled with the immersed structure described by Lagrangian variables via the use of the Dirac delta function. From a numerical standpoint, the Lagrangian force spreading and the Eulerian velocity interpolation are carried out by a regularized, compactly supported discrete delta function, which is assumed to be a tensor product of a single-variable immersed-boundary kernel. IB kernels are derived from a set of postulates designed to achieve approximate grid translational invariance, interpolation accuracy and computational efficiency. In this note, we present a new 6-point immersed-boundary kernel that is C3 and yields a substantially improved translational invariance compared to other common IB kernels.}
}

@article{Yang2009,
title = {A smoothing technique for discrete delta functions with application to immersed boundary method in moving boundary simulations},
journal = {Journal of Computational Physics},
volume = {228},
number = {20},
pages = {7821-7836},
year = {2009},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2009.07.023},
url = {https://www.sciencedirect.com/science/article/pii/S0021999109004136},
author = {Xiaolei Yang and Xing Zhang and Zhilin Li and Guo-Wei He},
keywords = {Immersed boundary method, Moving boundary, Non-physical force oscillations, Smoothed discrete delta function},
abstract = {The effects of complex boundary conditions on flows are represented by a volume force in the immersed boundary methods. The problem with this representation is that the volume force exhibits non-physical oscillations in moving boundary simulations. A smoothing technique for discrete delta functions has been developed in this paper to suppress the non-physical oscillations in the volume forces. We have found that the non-physical oscillations are mainly due to the fact that the derivatives of the regular discrete delta functions do not satisfy certain moment conditions. It has been shown that the smoothed discrete delta functions constructed in this paper have one-order higher derivative than the regular ones. Moreover, not only the smoothed discrete delta functions satisfy the first two discrete moment conditions, but also their derivatives satisfy one-order higher moment condition than the regular ones. The smoothed discrete delta functions are tested by three test cases: a one-dimensional heat equation with a moving singular force, a two-dimensional flow past an oscillating cylinder, and the vortex-induced vibration of a cylinder. The numerical examples in these cases demonstrate that the smoothed discrete delta functions can effectively suppress the non-physical oscillations in the volume forces and improve the accuracy of the immersed boundary method with direct forcing in moving boundary simulations.}
}

@article{Shamshirgar2021,
author = {Shamshirgar,D. S.  and Bagge,J.  and Tornberg,A.-K. },
title = {Fast Ewald summation for electrostatic potentials with arbitrary periodicity},
journal = {The Journal of Chemical Physics},
volume = {154},
number = {16},
pages = {164109},
year = {2021},
doi = {10.1063/5.0044895},
URL = {https://doi.org/10.1063/5.0044895},
eprint = {https://doi.org/10.1063/5.0044895}
}


@article{Barnett2019,
author = {Barnett, Alexander H. and Magland, Jeremy and af Klinteberg, Ludvig},
title = {A Parallel Nonuniform Fast Fourier Transform Library Based on an “Exponential of Semicircle" Kernel},
journal = {SIAM Journal on Scientific Computing},
volume = {41},
number = {5},
pages = {C479-C504},
year = {2019},
doi = {10.1137/18M120885X},
URL = {https://doi.org/10.1137/18M120885X},
eprint = {https://doi.org/10.1137/18M120885X}
}

@article{Shih2021,
title={cuFINUFFT: a load-balanced GPU library for general-purpose nonuniform FFTs}, 
author={Yu-hsuan Shih and Garrett Wright and Joakim Andén and Johannes Blaschke and Alex H. Barnett},
year={2021},
eprint={2102.08463},
archivePrefix={arXiv},
}
@misc{Barnett2020,
      title={Aliasing error of the exp$(\beta \sqrt{1-z^2})$ kernel in the nonuniform fast Fourier transform}, 
      author={A. H. Barnett},
      year={2020},
      eprint={2001.09405},
      archivePrefix={arXiv},
      primaryClass={math.NA}
}
@article{Guo2015,
title = {Efficient Particle-mesh Spreading on GPUs},
journal = {Procedia Computer Science},
volume = {51},
pages = {120-129},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {10.1016/j.procs.2015.05.210},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915010182},
author = {Xiangyu Guo and Xing Liu and Peng Xu and Zhihui Du and Edmond Chow},
keywords = {Particle-mesh, Spreading, Interpolation, Sparse matrices, GPU, Warp shuffle},
abstract = {The particle-mesh spreading operation maps a value at an arbitrary particle position to contributions at regular positions on a mesh. This operation is often used when a calculation involving irregular positions is to be performed in Fourier space. We study several approaches for particle-mesh spreading on GPUs. A central concern is the use of atomic operations. We are also concerned with the case where spreading is performed multiple times using the same particle configuration, which opens the possibility of preprocessing to accelerate the overall computation time. Experimental tests show which algorithms are best under which circumstances.}
}